# ğŸš€ AI ê¸°ë°˜ ì†Œìƒê³µì¸ ì°½ì—… ì»¨ì„¤íŒ… ì‹œìŠ¤í…œ

> ML ì˜ˆì¸¡ + RAG + LLM í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜
>
> ê³µê³µë°ì´í„° ê¸°ë°˜ ìƒê°€ ë¶„ì„ â†’ XGBoost/PyTorch ì˜ˆì¸¡ â†’ ë¡œì»¬ LLM ìì—°ì–´ ì»¨ì„¤íŒ…

---

## ì „ì²´ ì‹¤í–‰ ìˆœì„œ ìš”ì•½

```
1. make install           # ì˜ì¡´ì„± ì„¤ì¹˜ (ìµœì´ˆ 1íšŒ)
2. make db-up             # MySQL Docker ì‹œì‘
3. make collect           # ìƒê°€ ë°ì´í„° ìˆ˜ì§‘ (API í‚¤ í•„ìš”)
4. make db-migrate        # CSV â†’ MySQL ë§ˆì´ê·¸ë ˆì´ì…˜
5. make setup-ollama      # Ollama í•œêµ­ì–´ ëª¨ë¸ ì„¤ì¹˜ (ìµœì´ˆ 1íšŒ)
6. make build-rag         # RAG ë²¡í„°DB êµ¬ì¶•
7. make train             # XGBoost ëª¨ë¸ í•™ìŠµ
8. make evaluate          # ëª¨ë¸ í‰ê°€
9. make serve             # API ì„œë²„ â†’ localhost:8000/docs
```

---

## 0ë‹¨ê³„. ì´ˆê¸° ì„¤ì •

```bash
# í”„ë¡œì íŠ¸ í´ë¡  í›„ ìµœì´ˆ 1íšŒ
cp .env.example .env           # í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ìƒì„±
vi .env                         # API í‚¤ ì…ë ¥ (data.go.krì—ì„œ ë°œê¸‰)
make install                    # ì˜ì¡´ì„± ì„¤ì¹˜
```

### .env ì„¤ì •

```env
PUBLIC_DATA_SERVICE_KEY=your_key_here     # ê³µê³µë°ì´í„° API í‚¤ (í•„ìˆ˜)
NTS_API_KEY=your_key_here                 # êµ­ì„¸ì²­ API í‚¤ (ì„ íƒ)
REGION_CODE_API_KEY=your_key_here         # í–‰ì •ë™ì½”ë“œ API í‚¤ (ì„ íƒ)
DATABASE_URL=mysql+pymysql://startup:startup1234@localhost:3306/startup_consultant
```

---

## 1ë‹¨ê³„. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •

```bash
# MySQL Docker ì»¨í…Œì´ë„ˆ ì‹œì‘
make db-up

# ì¤‘ì§€
make db-down
```

| í•­ëª© | ë‚´ìš© |
|------|------|
| ì„¤ì • íŒŒì¼ | `docker-compose.yml` |
| ì´ˆê¸°í™” SQL | `docker/init.sql` (í…Œì´ë¸” ìë™ ìƒì„±) |
| ì ‘ì† ì •ë³´ | `localhost:3306`, user: `startup`, pw: `startup1234` |
| DBëª… | `startup_consultant` |
| í…Œì´ë¸” | `stores` (ìƒê°€), `region_codes` (í–‰ì •ë™), `collection_logs` (ìˆ˜ì§‘ ì´ë ¥) |

---

## 2ë‹¨ê³„. ë°ì´í„° ìˆ˜ì§‘

```bash
# í–‰ì •ë™ì½”ë“œ ìˆ˜ì§‘ (API í‚¤ ë¶ˆí•„ìš”)
make collect-hdong

# ìƒê°€ ë°ì´í„° ìˆ˜ì§‘ (ì„œìš¸ ì „ì²´)
make collect

# íŠ¹ì • í–‰ì •ë™ë§Œ ìˆ˜ì§‘ (í…ŒìŠ¤íŠ¸)
python scripts/run_collect.py --codes 11680640 --limit 1

# CSV â†’ MySQL ë§ˆì´ê·¸ë ˆì´ì…˜
make db-migrate
```

| í•­ëª© | ë‚´ìš© |
|------|------|
| ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ | `scripts/run_collect.py` |
| í˜¸ì¶œ í´ë˜ìŠ¤ | `src/data_collection/collector.py â†’ DataCollector` |
| API | ì†Œìƒê³µì¸ì§„í¥ê³µë‹¨ ìƒê°€ì •ë³´ (`adongCd` 8ìë¦¬) + êµ­ì„¸ì²­ ì‚¬ì—…ì ìƒíƒœ |
| ì¶œë ¥ (CSV) | `data/01_raw/stores_raw.csv` |
| ì¶œë ¥ (DB) | `stores` í…Œì´ë¸” (UPSERT, ì¤‘ë³µ ë°©ì§€) |
| í–‰ì •ë™ì½”ë“œ | `data/00_region_codes/hdong_codes_11.csv` (PublicDataReader) |
| í•„ìˆ˜ ì¡°ê±´ | `.env`ì— `PUBLIC_DATA_SERVICE_KEY` ì…ë ¥ |

> âš ï¸ API í‚¤ê°€ ì—†ì–´ë„ 3ë‹¨ê³„ë¶€í„°ëŠ” ë”ë¯¸ ë°ì´í„°ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

## 3ë‹¨ê³„. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§

```bash
make feature
```

| í•­ëª© | ë‚´ìš© |
|------|------|
| ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ | `scripts/run_feature.py` |
| íŒŒì´í”„ë¼ì¸ | `DataCleaner â†’ LabelGenerator â†’ FeatureBuilder â†’ FeatureStore` |
| ì…ë ¥ | `data/01_raw/stores_raw.csv` ë˜ëŠ” MySQL `stores` í…Œì´ë¸” |
| ì¶œë ¥ | `data/05_model_input/X_train.npy, y_train.npy` ë“± |
| í”¼ì²˜ ìˆ˜ | 22ê°œ (ì—…ì¢… ì¸ì½”ë”©, ì§€ì—­ í†µê³„, ê²½ìŸì—…ì²´ ë°€ë„, ì°½ì—…ì í”„ë¡œí•„ ë“±) |

---

## 4ë‹¨ê³„. ëª¨ë¸ í•™ìŠµ

```bash
# XGBoost (ê¸°ë³¸ â€” ë¹ ë¥´ê³  ì •í˜• ë°ì´í„°ì— ê°•í•¨)
make train

# PyTorch ë”¥ëŸ¬ë‹ (ë°ì´í„° 10ë§Œê±´ ì´ìƒì¼ ë•Œ ìœ ë¦¬)
make train-dl

# ì§ì ‘ ë°ì´í„° íŒŒì¼ ì§€ì •
python scripts/run_train.py --model xgboost --data data/01_raw/my_data.csv
```

| í•­ëª© | ë‚´ìš© |
|------|------|
| ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ | `scripts/run_train.py` |
| íŒŒì´í”„ë¼ì¸ | `pipelines/train_pipeline.py â†’ TrainPipeline` |
| ë°ì´í„° íë¦„ | ë¡œë“œ â†’ ì •ì œ â†’ ë¼ë²¨ â†’ í”¼ì²˜ â†’ ë¶„í•  â†’ í•™ìŠµ â†’ í‰ê°€ â†’ ì €ì¥ |
| ì¶œë ¥ ëª¨ë¸ | `models/registry/best_model.pkl` (.pt for PyTorch) |
| ì¶œë ¥ ì „ì²˜ë¦¬ê¸° | `models/artifacts/scaler.pkl, label_encoders.pkl` |
| í‰ê°€ ë¦¬í¬íŠ¸ | `logs/eval_report.json` |
| ì†Œìš” ì‹œê°„ | XGBoost: ~4ì´ˆ, DL: ~30ì´ˆ (5,000ê±´ ê¸°ì¤€) |

---

## 5ë‹¨ê³„. ëª¨ë¸ í‰ê°€

```bash
# ëª¨ë“  ëª¨ë¸ ìë™ íƒì§€ & í‰ê°€
make evaluate

# íŠ¹ì • ëª¨ë¸ë§Œ
python scripts/run_evaluate.py --model xgboost
python scripts/run_evaluate.py --model neural_net
```

| í•­ëª© | ë‚´ìš© |
|------|------|
| ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ | `scripts/run_evaluate.py` |
| ì—­í•  | ì €ì¥ëœ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€ + ëª¨ë¸ ê°„ ë¹„êµ |
| í‰ê°€ ë©”íŠ¸ë¦­ | ìƒì¡´ ì •í™•ë„/F1/AUC, ë§¤ì¶œ MAE/RÂ², ë¦¬ìŠ¤í¬ MAE |
| ì¶œë ¥ | `logs/eval_xgboost.json`, `logs/eval_neural_net.json`, `logs/eval_comparison.json` |
| ì „ì œ ì¡°ê±´ | `make train`ì„ ë¨¼ì € ì‹¤í–‰í•´ì•¼ ëª¨ë¸ì´ ìˆìŒ |

---

## 6ë‹¨ê³„. LLM & RAG ì„¤ì •

```bash
# Ollama ì„¤ì¹˜ (macOS)
brew install ollama

# í•œêµ­ì–´ ëª¨ë¸ ì„¤ì¹˜ (5.4GB, 1íšŒ)
make setup-ollama
# ë˜ëŠ”: ollama pull gemma2:9b

# ì„ë² ë”© ëª¨ë¸ ì„¤ì¹˜ (RAGìš©, 274MB)
ollama pull nomic-embed-text

# RAG ë²¡í„°DB êµ¬ì¶• (í…ŒìŠ¤íŠ¸: 1000ê±´)
make build-rag-test

# RAG ë²¡í„°DB êµ¬ì¶• (ì „ì²´)
make build-rag

# RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
python scripts/run_build_rag.py --query "ê°•ë‚¨êµ¬ ì¹´í˜"
```

| í•­ëª© | ë‚´ìš© |
|------|------|
| LLM ëª¨ë¸ | Ollama gemma2:9b (í•œêµ­ì–´ ìë™ íƒì§€, ì™„ì „ ë¡œì»¬, ë¬´ë£Œ) |
| ì„ë² ë”© ëª¨ë¸ | nomic-embed-text (274MB) |
| ë²¡í„°DB | ChromaDB (`data/06_vector_db/`) |
| í”„ë¡¬í”„íŠ¸ ê°•í™” | A) DataContext (ì—…ì¢…/ì§€ì—­ í†µê³„) + B) RAGStore (ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰) |
| êµ¬ì¶• ìŠ¤í¬ë¦½íŠ¸ | `scripts/run_build_rag.py` |

### í•œêµ­ì–´ ëª¨ë¸ ìš°ì„ ìˆœìœ„ (ìë™ íƒì§€)

| ìˆœìœ„ | ëª¨ë¸ | í¬ê¸° | í•œêµ­ì–´ |
|------|------|------|--------|
| 1 | EEVE-Korean-10.8B | 6.5GB | ìµœê³  |
| 2 | gemma2:9b | 5.4GB | ì¢‹ìŒ |
| 3 | llama3.1:8b | 4.7GB | ë³´í†µ |

---

## 7ë‹¨ê³„. API ì„œë²„ ì‹¤í–‰

```bash
# Ollama ì„œë²„ ì‹œì‘ (í„°ë¯¸ë„ 1)
ollama serve

# API ì„œë²„ ì‹œì‘ (í„°ë¯¸ë„ 2)
make serve
```

| í•­ëª© | ë‚´ìš© |
|------|------|
| ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ | `scripts/run_server.py` |
| í”„ë ˆì„ì›Œí¬ | FastAPI + Uvicorn |
| ì£¼ì†Œ | `http://localhost:8000` |
| Swagger ë¬¸ì„œ | `http://localhost:8000/docs` â† ì—¬ê¸°ì„œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ |
| ì „ì œ ì¡°ê±´ | `make train` (ëª¨ë¸) + `ollama serve` (LLM) |

### API ì—”ë“œí¬ì¸íŠ¸

| Method | Path | ì„¤ëª… |
|--------|------|------|
| GET | `/health` | ì„œë²„ ìƒíƒœ + í™œì„± LLM í™•ì¸ |
| POST | `/api/v1/predict` | ML ì˜ˆì¸¡ë§Œ (ìˆ«ì ê²°ê³¼) |
| POST | `/api/v1/consult` | ML ì˜ˆì¸¡ + LLM ì¢…í•© ì»¨ì„¤íŒ… ë¦¬í¬íŠ¸ |
| POST | `/api/v1/strategy` | ë§ì¶¤í˜• ì „ëµ ì œì•ˆ |
| POST | `/api/v1/ask` | Q&A ëŒ€í™” |
| POST | `/api/v1/competitors` | ê²½ìŸì—…ì²´ ë¶„ì„ |

### ì»¨ì„¤íŒ… API í˜¸ì¶œ ì˜ˆì‹œ (curl)

```bash
curl -X POST http://localhost:8000/api/v1/consult \
  -H "Content-Type: application/json" \
  -d '{
    "founder_age": 35,
    "founder_gender": "M",
    "founder_education": "bachelor",
    "experience_years": 5,
    "has_related_experience": true,
    "business_category": "food",
    "business_sub_category": "cafe",
    "initial_investment": 50000000,
    "monthly_rent": 2000000,
    "store_size_sqm": 33.0,
    "employee_count": 2,
    "is_franchise": false,
    "district": "ì—­ì‚¼1ë™"
  }'
```

### ì‘ë‹µ ì˜ˆì‹œ

```json
{
  "success": true,
  "llm_provider": "Ollama (gemma2:9b)",
  "prediction": {
    "survival": { "one_year": 0.7234, "three_year": 0.4891 },
    "financials": {
      "monthly_revenue": 15230000,
      "monthly_profit": 3120000,
      "break_even_months": 16
    },
    "risk": {
      "score": 0.3521,
      "level": "MEDIUM",
      "factors": ["ê²½ìŸ ê³¼ë°€ ì§€ì—­ì…ë‹ˆë‹¤"]
    }
  },
  "analysis": "## ì¢…í•© í‰ê°€\nì—­ì‚¼1ë™ì—ì„œ ì¹´í˜ ì°½ì—…ì„ ê³„íší•˜ê³  ê³„ì‹œêµ°ìš”. í•´ë‹¹ ì§€ì—­ì—ëŠ” í˜„ì¬ ìŒì‹ ì—…ì¢… ìƒê°€ê°€ 234ê°œ ìš´ì˜ ì¤‘ì´ë©°..."
}
```

---

## 8ë‹¨ê³„. í…ŒìŠ¤íŠ¸

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸
make test

# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë§Œ
make test-unit

# í†µí•© í…ŒìŠ¤íŠ¸ë§Œ
make test-integ
```

| í•­ëª© | ë‚´ìš© |
|------|------|
| í”„ë ˆì„ì›Œí¬ | pytest |
| ê³µí†µ í”½ìŠ¤ì²˜ | `tests/conftest.py` (ìƒ˜í”Œ ë°ì´í„°, í•™ìŠµëœ ëª¨ë¸) |
| ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ | `tests/unit/test_features.py`, `test_models.py` |
| í†µí•© í…ŒìŠ¤íŠ¸ | `tests/integration/test_pipeline.py` |

---

## ê¸°íƒ€ ëª…ë ¹ì–´

```bash
make help               # ì „ì²´ ëª…ë ¹ì–´ ë„ì›€ë§
make clean              # ìºì‹œ/ì„ì‹œ íŒŒì¼ ì •ë¦¬
make collect-regions    # ë²•ì •ë™ì½”ë“œ ìˆ˜ì§‘ (í–‰ì •í‘œì¤€ì½”ë“œ API)
make collect-hdong      # í–‰ì •ë™ì½”ë“œ ìˆ˜ì§‘ (PublicDataReader)
```

---

## íŒŒì¼ íë¦„ë„

```
make collect
  â””â†’ scripts/run_collect.py
      â””â†’ src/data_collection/collector.py
          â”œâ†’ public_data_client.py  (ìƒê°€ ë°ì´í„°, adongCd 8ìë¦¬)
          â””â†’ nts_client.py          (ì‚¬ì—…ì ìƒíƒœ, ì—°ì†ì‹¤íŒ¨ 3íšŒ ì¡°ê¸°ì¤‘ë‹¨)
      â””â†’ ì¶œë ¥: data/01_raw/stores_raw.csv

make db-migrate
  â””â†’ scripts/run_migrate_to_db.py
      â””â†’ src/database/repository.py
          â”œâ†’ StoreRepository.upsert_stores()   â†’ stores í…Œì´ë¸”
          â””â†’ RegionRepository.upsert_regions() â†’ region_codes í…Œì´ë¸”

make train
  â””â†’ scripts/run_train.py (OMP_NUM_THREADS=1)
      â””â†’ pipelines/train_pipeline.py
          â”œâ†’ src/preprocessing/cleaner.py      â†’ data/02_interim/
          â”œâ†’ src/preprocessing/labeler.py      â†’ data/03_processed/
          â”œâ†’ src/features/builder.py           â†’ data/04_features/
          â”œâ†’ src/features/store.py             â†’ data/05_model_input/
          â”œâ†’ src/models/xgboost_model.py       â†’ models/registry/
          â””â†’ src/evaluation/metrics.py         â†’ logs/eval_report.json

make build-rag
  â””â†’ scripts/run_build_rag.py
      â””â†’ src/llm/rag_store.py
          â”œâ†’ stores_raw.csv â†’ í…ìŠ¤íŠ¸ ë³€í™˜
          â”œâ†’ Ollama nomic-embed-text ì„ë² ë”©
          â””â†’ ChromaDB ì €ì¥ â†’ data/06_vector_db/

make serve
  â””â†’ scripts/run_server.py
      â””â†’ src/serving/app.py
          â”œâ†’ dependencies.py â†’ Predictor (ML ëª¨ë¸ ë¡œë“œ)
          â”œâ†’ dependencies.py â†’ Consultant (LLM + DataContext + RAG)
          â”œâ†’ predictor.py    â†’ ML ì˜ˆì¸¡
          â””â†’ consultant.py   â†’ í†µê³„(A) + RAG(B) + LLM â†’ ìì—°ì–´ ë¦¬í¬íŠ¸
```

---

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€ ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ê³µê³µë°ì´í„° API â†’ CSV â†’ MySQL (UPSERT ì¤‘ë³µ ë°©ì§€)   â”‚
â”‚ - stores: ìƒê°€ ì›ë³¸ ë°ì´í„°                        â”‚
â”‚ - region_codes: í–‰ì •ë™ ë§ˆìŠ¤í„°                     â”‚
â”‚ - collection_logs: ìˆ˜ì§‘ ì´ë ¥                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ ì „ì²˜ë¦¬ & í•™ìŠµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MySQL â†’ DataFrame â†’ í”¼ì²˜/ë¼ë²¨ â†’ XGBoost/PyTorch  â”‚
â”‚                               â†’ ChromaDB (RAG)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€ LLM ì„œë¹™ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API ìš”ì²­ â†’ ML ì˜ˆì¸¡                               â”‚
â”‚          + A) DataContext (ì—…ì¢…/ì§€ì—­ í†µê³„)         â”‚
â”‚          + B) RAGStore (ChromaDB ìœ ì‚¬ ì‚¬ë¡€)       â”‚
â”‚          â†’ Ollama gemma2:9b â†’ ìì—°ì–´ ë‹µë³€         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```