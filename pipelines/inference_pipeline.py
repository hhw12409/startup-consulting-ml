"""
ğŸ“ pipelines/inference_pipeline.py
====================================
ì¶”ë¡  íŒŒì´í”„ë¼ì¸.

[íŒ¨í„´] Chain of Responsibility â€” ì…ë ¥ â†’ ê²€ì¦ â†’ ì „ì²˜ë¦¬ â†’ ì¶”ë¡  â†’ í›„ì²˜ë¦¬
[ì—­í• ] APIê°€ ì•„ë‹Œ ë°°ì¹˜ ì¶”ë¡ ì´ë‚˜ ë…¸íŠ¸ë¶ì—ì„œ ì§ì ‘ ì‚¬ìš©í•  ë•Œ í¸ë¦¬í•©ë‹ˆë‹¤.

API ì„œë¹™(serving/predictor.py)ì€ HTTP ìš”ì²­ ì²˜ë¦¬ì— íŠ¹í™”ë˜ì–´ ìˆê³ ,
ì´ íŒŒì´í”„ë¼ì¸ì€ ìˆœìˆ˜ Python í•¨ìˆ˜ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

from typing import Optional
import pandas as pd
import numpy as np

from src.models.base import BaseModel
from src.features.builder import FeatureBuilder
from src.utils.logger import get_logger

logger = get_logger(__name__)


class InferencePipeline:
    """
    ì¶”ë¡  íŒŒì´í”„ë¼ì¸.

    ì‚¬ìš©ë²•:
        # ë‹¨ê±´ ì¶”ë¡ 
        pipeline = InferencePipeline(model, builder)
        result = pipeline.predict_single({"age": 35, "business_category": "food", ...})

        # ë°°ì¹˜ ì¶”ë¡ 
        results = pipeline.predict_batch(df)
    """

    def __init__(self, model: BaseModel, feature_builder: FeatureBuilder):
        self._model = model
        self._builder = feature_builder

    def predict_single(self, input_data: dict) -> dict:
        """
        ë‹¨ê±´ ì¶”ë¡ .

        Args:
            input_data: ì›ë³¸ ì…ë ¥ ë”•ì…”ë„ˆë¦¬

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        df = pd.DataFrame([input_data])
        results = self.predict_batch(df)
        return results[0] if results else {}

    def predict_batch(self, df: pd.DataFrame) -> list[dict]:
        """
        ë°°ì¹˜ ì¶”ë¡ .

        Args:
            df: ì—¬ëŸ¬ ê±´ì˜ ì…ë ¥ DataFrame

        Returns:
            ê° ê±´ë³„ ì˜ˆì¸¡ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        logger.info("ë°°ì¹˜ ì¶”ë¡ : %dê±´", len(df))

        # 1) ì „ì²˜ë¦¬
        X = self._builder.transform(df)

        # 2) ëª¨ë¸ ì¶”ë¡ 
        raw = self._model.predict(X)

        # 3) í›„ì²˜ë¦¬: ê° í–‰ë³„ë¡œ ê²°ê³¼ ìƒì„±
        results = []
        for i in range(len(df)):
            result = {
                "survival_1yr": float(raw["survival"][i, 0]),
                "survival_3yr": float(raw["survival"][i, 1]),
                "monthly_revenue": int(raw["revenue"][i, 0]),
                "monthly_profit": int(raw["revenue"][i, 1]),
                "risk_score": float(raw["risk"][i, 0]),
                "break_even_months": max(1, int(raw["break_even"][i, 0])),
            }

            # ë¦¬ìŠ¤í¬ ë“±ê¸‰
            rs = result["risk_score"]
            result["risk_level"] = (
                "LOW" if rs < 0.3 else
                "MEDIUM" if rs < 0.6 else
                "HIGH" if rs < 0.8 else
                "CRITICAL"
            )

            results.append(result)

        logger.info("ë°°ì¹˜ ì¶”ë¡  ì™„ë£Œ: %dê±´", len(results))
        return results

    @classmethod
    def from_saved(
            cls,
            model_path: str = None,
            artifact_path: str = None,
            model_type: str = "xgboost",
    ) -> "InferencePipeline":
        """
        [íŒ¨í„´] Factory Method -- ì €ì¥ëœ ëª¨ë¸ì—ì„œ íŒŒì´í”„ë¼ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.

        ê²½ë¡œë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ DBì˜ training_runsì—ì„œ ìµœì‹  ëª¨ë¸ì„ ì¡°íšŒí•©ë‹ˆë‹¤.

        ì‚¬ìš©ë²•:
            # ì§ì ‘ ì§€ì •
            pipeline = InferencePipeline.from_saved(
                model_path="models/registry/best_model",
                artifact_path="models/artifacts/",
            )

            # DBì—ì„œ ìµœì‹  ëª¨ë¸ ìë™ ì¡°íšŒ
            pipeline = InferencePipeline.from_saved()
        """
        # DBì—ì„œ ìµœì‹  í•™ìŠµ ì‹¤í–‰ ì¡°íšŒ (ê²½ë¡œ ë¯¸ì§€ì • ì‹œ)
        if not model_path or not artifact_path:
            try:
                from src.database.repository import TrainingRunRepository
                repo = TrainingRunRepository()
                latest = repo.get_latest_run(model_type=model_type)
                if latest:
                    model_path = model_path or latest.model_path
                    artifact_path = artifact_path or latest.artifacts_path
                    logger.info("DBì—ì„œ ìµœì‹  ëª¨ë¸ ì¡°íšŒ: run=%s", latest.run_id[:8])
            except Exception as e:
                logger.warning("DB ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨: %s", e)

        # ê¸°ë³¸ ê²½ë¡œ fallback
        from config.settings import get_settings
        settings = get_settings()
        model_path = model_path or f"{settings.MODEL_REGISTRY}/best_model"
        artifact_path = artifact_path or settings.MODEL_ARTIFACTS

        if model_type == "xgboost":
            from src.models.xgboost_model import XGBoostModel
            model = XGBoostModel()
        else:
            from src.models.neural_net import NeuralNetModel
            model = NeuralNetModel()

        model.load(model_path)
        builder = FeatureBuilder.load_artifacts(artifact_path)

        logger.info("ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ìƒì„±: model=%s", model.name)
        return cls(model, builder)