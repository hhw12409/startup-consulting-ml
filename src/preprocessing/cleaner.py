"""
ğŸ“ src/preprocessing/cleaner.py
================================
ë°ì´í„° ì •ì œ ëª¨ë“ˆ.

[ì—­í• ] API ì›ë³¸ ì»¬ëŸ¼ ë§¤í•‘ â†’ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ â†’ ì´ìƒì¹˜ ì œê±° â†’ íƒ€ì… ë³€í™˜
[ìœ„ì¹˜] 01_raw â†’ 02_interim ë‹¨ê³„

[í•µì‹¬ ìˆ˜ì •ì‚¬í•­]
ê³µê³µë°ì´í„° API ì›ë³¸ CSVëŠ” 'bizesNm', 'indsLclsCdNm' ê°™ì€ ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
ìš°ë¦¬ ëª¨ë¸ì€ 'age', 'business_category' ê°™ì€ ì»¬ëŸ¼ëª…ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤.
ì´ ëª¨ë“ˆì—ì„œ ì»¬ëŸ¼ëª…ì„ ë§¤í•‘í•˜ê³ , ì—†ëŠ” í”¼ì²˜ëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np

from config.feature_config import FEATURE_CONFIG
from src.utils.logger import get_logger

logger = get_logger(__name__)


# ================================================================
# ê³µê³µë°ì´í„° API ì›ë³¸ ì»¬ëŸ¼ â†’ ìš°ë¦¬ ì»¬ëŸ¼ ë§¤í•‘
# ================================================================
API_COLUMN_MAP = {
    # ê³µê³µë°ì´í„° API ì»¬ëŸ¼ëª…       â†’ ìš°ë¦¬ í”¼ì²˜ëª…
    "indsLclsCdNm":               "business_category",       # ì—…ì¢… ëŒ€ë¶„ë¥˜ëª…
    "indsLclsNm":                 "business_category",       # CSV í˜¸í™˜ (CdNm ì—†ëŠ” ê²½ìš°)
    "indsMclsCdNm":               "business_sub_category",   # ì—…ì¢… ì¤‘ë¶„ë¥˜ëª…
    "indsMclsNm":                 "business_sub_category",   # CSV í˜¸í™˜
    "adongNm":                    "district",                # í–‰ì •ë™ëª…
    "adongCd":                    "dong_code",               # í–‰ì •ë™ì½”ë“œ
    "lon":                        "longitude",               # ê²½ë„
    "lat":                        "latitude",                # ìœ„ë„
    "bizesNm":                    "store_name",              # ìƒí˜¸ëª…
    "bizesId":                    "biz_id",                  # ì‚¬ì—…ìë²ˆí˜¸
    "rdnmAdr":                    "road_address",            # ë„ë¡œëª…ì£¼ì†Œ
    "lnoAdr":                     "lot_address",             # ì§€ë²ˆì£¼ì†Œ
}

# DB(stores í…Œì´ë¸”) ì»¬ëŸ¼ëª… â†’ ìš°ë¦¬ í”¼ì²˜ëª…
DB_COLUMN_MAP = {
    "category_large":             "business_category",       # ì—…ì¢… ëŒ€ë¶„ë¥˜ëª…
    "category_mid":               "business_sub_category",   # ì—…ì¢… ì¤‘ë¶„ë¥˜ëª…
    "adong_name":                 "district",                # í–‰ì •ë™ëª…
    "adong_cd":                   "dong_code",               # í–‰ì •ë™ì½”ë“œ
}


class DataCleaner:
    """
    ë°ì´í„° ì •ì œê¸°.

    ê³µê³µë°ì´í„° ì›ë³¸ CSVì™€ ë”ë¯¸ ë°ì´í„° ëª¨ë‘ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤.

    ì‚¬ìš©ë²•:
        cleaner = DataCleaner()
        df_clean = cleaner.clean(df_raw)
    """

    def clean(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ì „ì²´ ì •ì œ íŒŒì´í”„ë¼ì¸.

        ë‹¨ê³„:
        0. API ì›ë³¸ ì»¬ëŸ¼ ë§¤í•‘ (ê³µê³µë°ì´í„°ì¸ ê²½ìš°)
        1. ì¤‘ë³µ ì œê±°
        2. ëˆ„ë½ í”¼ì²˜ ê¸°ë³¸ê°’ ì±„ìš°ê¸°
        3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        4. ì´ìƒì¹˜ ì œê±°
        5. íƒ€ì… ë³€í™˜
        """
        df = df.copy()
        original_len = len(df)

        # Step 0: API ì›ë³¸ ì»¬ëŸ¼ëª…ì´ë©´ ë§¤í•‘
        df = self._map_api_columns(df)

        # Step 1: ì¤‘ë³µ ì œê±°
        df = df.drop_duplicates()
        if len(df) < original_len:
            logger.info("ì¤‘ë³µ ì œê±°: %d â†’ %dí–‰", original_len, len(df))

        # Step 2: ëˆ„ë½ í”¼ì²˜ ê¸°ë³¸ê°’ ì±„ìš°ê¸°
        df = self._fill_missing_features(df)

        # Step 3: ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df = self._fill_missing(df)

        # Step 4: ì´ìƒì¹˜ ì œê±°
        df = self._remove_outliers(df)

        # Step 5: íƒ€ì… ë³€í™˜
        df = self._cast_types(df)

        logger.info("ì •ì œ ì™„ë£Œ: %dí–‰ Ã— %dì—´", *df.shape)
        return df

    def _map_api_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ì›ë³¸ ì»¬ëŸ¼ëª… â†’ ìš°ë¦¬ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€í™˜.

        ê³µê³µë°ì´í„° API ì»¬ëŸ¼(adongNm ë“±) ë˜ëŠ”
        DB ì»¬ëŸ¼(adong_name ë“±)ì„ ê°ì§€í•˜ì—¬ ìë™ ë§¤í•‘í•©ë‹ˆë‹¤.
        ì´ë¯¸ ìš°ë¦¬ ì»¬ëŸ¼ëª…ì´ë©´ ì•„ë¬´ê²ƒë„ ì•ˆ í•©ë‹ˆë‹¤.
        """
        rename_map = {}

        # 1) ê³µê³µë°ì´í„° API ì›ë³¸ ì»¬ëŸ¼ ë§¤í•‘
        api_cols = set(API_COLUMN_MAP.keys()) & set(df.columns)
        if api_cols:
            rename_map.update({k: v for k, v in API_COLUMN_MAP.items() if k in df.columns})
            logger.info("ê³µê³µë°ì´í„° API ì»¬ëŸ¼ ê°ì§€ (%dê°œ)", len(api_cols))

        # 2) DB(stores í…Œì´ë¸”) ì»¬ëŸ¼ ë§¤í•‘
        db_cols = set(DB_COLUMN_MAP.keys()) & set(df.columns)
        if db_cols:
            # ì´ë¯¸ ë§¤í•‘ ëŒ€ìƒ ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ë©´ ê±´ë„ˆëœ€ (ì¤‘ë³µ ë°©ì§€)
            for k, v in DB_COLUMN_MAP.items():
                if k in df.columns and v not in df.columns and k not in rename_map:
                    rename_map[k] = v
            if db_cols - set(rename_map.keys()) != db_cols:
                logger.info("DB ì»¬ëŸ¼ ê°ì§€ (%dê°œ)", len(db_cols))

        if not rename_map:
            logger.debug("ë§¤í•‘ ëŒ€ìƒ ì»¬ëŸ¼ ì—†ìŒ â†’ ê±´ë„ˆëœ€")
            return df

        df = df.rename(columns=rename_map)
        logger.info("ì»¬ëŸ¼ ë§¤í•‘ ì™„ë£Œ: %s", list(rename_map.values()))
        return df

    def _fill_missing_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” í”¼ì²˜ê°€ dfì— ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.

        ê³µê³µë°ì´í„° APIì—ëŠ” 'age', 'experience_years' ê°™ì€ ì°½ì—…ì ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.
        ì´ëŸ° í”¼ì²˜ëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ì›Œì„œ ëª¨ë¸ì´ ë™ì‘í•˜ë„ë¡ í•©ë‹ˆë‹¤.
        ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•©ë‹ˆë‹¤.
        """
        defaults_numerical = {
            "age": 35,
            "experience_years": 3,
            "initial_investment": 50_000_000,
            "initial_capital": 50_000_000,
            "monthly_rent": 2_000_000,
            "store_size_sqm": 33.0,
            "employee_count": 1,
            "nearby_competitor_count": 5,
        }

        defaults_categorical = {
            "gender": "M",
            "education_level": "bachelor",
            "floating_population_level": "medium",
        }

        defaults_binary = {
            "has_related_experience": 0,
            "has_startup_experience": 0,
            "is_franchise": 0,
        }

        added = []
        for col, val in {**defaults_numerical, **defaults_categorical, **defaults_binary}.items():
            if col not in df.columns:
                df[col] = val
                added.append(col)

        if added:
            logger.info("ëˆ„ë½ í”¼ì²˜ ê¸°ë³¸ê°’ ì¶”ê°€ (%dê°œ): %s", len(added), added)

        return df

    def _fill_missing(self, df: pd.DataFrame) -> pd.DataFrame:
        """ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ìˆ˜ì¹˜í˜•: ì¤‘ì•™ê°’, ë²”ì£¼í˜•: 'unknown', ì´ì§„: 0)"""
        for col in FEATURE_CONFIG.numerical:
            if col in df.columns:
                median = df[col].median()
                nulls = df[col].isna().sum()
                if nulls > 0:
                    df[col] = df[col].fillna(median)
                    logger.debug("ê²°ì¸¡ì¹˜ ì±„ì›€: %s (%dê±´, median=%.1f)", col, nulls, median)

        for col in FEATURE_CONFIG.categorical:
            if col in df.columns:
                df[col] = df[col].fillna("unknown")

        for col in FEATURE_CONFIG.binary:
            if col in df.columns:
                df[col] = df[col].fillna(0)

        return df

    def _remove_outliers(self, df: pd.DataFrame) -> pd.DataFrame:
        """IQR ë°©ì‹ ì´ìƒì¹˜ ì œê±° (Q1 - 3*IQR ~ Q3 + 3*IQR)"""
        outlier_cols = ["initial_investment", "monthly_rent", "store_size_sqm"]

        for col in outlier_cols:
            if col not in df.columns:
                continue
            if not pd.api.types.is_numeric_dtype(df[col]):
                continue

            q1 = df[col].quantile(0.25)
            q3 = df[col].quantile(0.75)
            iqr = q3 - q1
            if iqr == 0:
                continue

            lower = q1 - 3 * iqr
            upper = q3 + 3 * iqr

            before = len(df)
            df = df[(df[col] >= lower) & (df[col] <= upper)]
            removed = before - len(df)
            if removed > 0:
                logger.info("ì´ìƒì¹˜ ì œê±°: %s (%dê±´)", col, removed)

        return df

    def _cast_types(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì»¬ëŸ¼ íƒ€ì…ì„ ëª…ì‹œì ìœ¼ë¡œ ë³€í™˜"""
        int_cols = ["age", "experience_years", "employee_count", "nearby_competitor_count"]
        float_cols = ["store_size_sqm", "initial_investment", "monthly_rent", "initial_capital"]

        for col in int_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).astype(int)

        for col in float_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).astype(float)

        return df