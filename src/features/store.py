"""
ğŸ“ src/features/store.py
=========================
í”¼ì²˜ ì €ì¥ì†Œ.

[íŒ¨í„´] Repository â€” í”¼ì²˜ ë°ì´í„°ì˜ ì €ì¥/ë¡œë“œë¥¼ ì¶”ìƒí™”
[ì—­í• ] train/val/test splitëœ ë°ì´í„°ë¥¼ numpyë¡œ ì €ì¥í•˜ê³  ë¡œë“œí•©ë‹ˆë‹¤.
"""

import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split

from config.settings import get_settings
from src.utils.logger import get_logger
from src.utils import io

logger = get_logger(__name__)


class FeatureStore:
    """
    í”¼ì²˜ ì €ì¥ì†Œ.

    ì‚¬ìš©ë²•:
        store = FeatureStore()
        store.save_splits(X, y)            # ìë™ split í›„ ì €ì¥
        X_train, y_train = store.load("train")  # ë¡œë“œ
    """

    def __init__(self, base_dir: str = None):
        self._dir = base_dir or get_settings().DATA_MODEL_INPUT

    def save_splits(
            self,
            X: np.ndarray,
            y: np.ndarray,
            val_ratio: float = 0.1,
            test_ratio: float = 0.1,
            random_state: int = 42,
    ) -> dict[str, int]:
        """
        Train/Val/Testë¡œ ë¶„í• í•˜ê³  05_model_input/ì— ì €ì¥í•©ë‹ˆë‹¤.

        Args:
            X, y: ì „ì²´ í”¼ì²˜ì™€ ë¼ë²¨
            val_ratio, test_ratio: ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¹„ìœ¨

        Returns:
            ê° ì„¸íŠ¸ì˜ í¬ê¸° {"train": 8000, "val": 1000, "test": 1000}
        """
        # Train+Val / Test ë¶„í• 
        X_train_val, X_test, y_train_val, y_test = train_test_split(
            X, y, test_size=test_ratio, random_state=random_state,
        )

        # Train / Val ë¶„í• 
        val_adjusted = val_ratio / (1 - test_ratio)
        X_train, X_val, y_train, y_val = train_test_split(
            X_train_val, y_train_val, test_size=val_adjusted, random_state=random_state,
        )

        # ì €ì¥
        Path(self._dir).mkdir(parents=True, exist_ok=True)
        for name, X_split, y_split in [
            ("train", X_train, y_train),
            ("val", X_val, y_val),
            ("test", X_test, y_test),
        ]:
            io.save_numpy(X_split, f"{self._dir}/X_{name}.npy")
            io.save_numpy(y_split, f"{self._dir}/y_{name}.npy")

        sizes = {"train": len(X_train), "val": len(X_val), "test": len(X_test)}
        logger.info("ë°ì´í„° ë¶„í•  ì €ì¥: %s", sizes)
        return sizes

    def save_splits_to_db(
            self,
            X: np.ndarray,
            y: np.ndarray,
            feature_columns: list[str],
            target_columns: list[str],
            pipeline_run_id: str,
            scaler_params: dict = None,
            encoder_classes: dict = None,
            val_ratio: float = 0.1,
            test_ratio: float = 0.1,
            random_state: int = 42,
    ) -> dict[str, int]:
        """
        ë°ì´í„°ë¥¼ ë¶„í• í•˜ì—¬ íŒŒì¼ + DBì— ë™ì‹œ ì €ì¥í•©ë‹ˆë‹¤.

        íŒŒì¼: ëª¨ë¸ í•™ìŠµì— ì§ì ‘ ì‚¬ìš© (numpy .npy)
        DB: í”¼ì²˜ì…‹ ë©”íƒ€ë°ì´í„° + BLOB ì¶”ì  (ì¬í˜„ì„±)

        Returns:
            ê° ì„¸íŠ¸ì˜ í¬ê¸° {"train": N, "val": N, "test": N}
        """
        # 1. íŒŒì¼ ì €ì¥ (ê¸°ì¡´ ë¡œì§)
        sizes = self.save_splits(X, y, val_ratio, test_ratio, random_state)

        # 2. DB ì €ì¥ (ì „ì²´ í”¼ì²˜ì…‹ ë©”íƒ€ë°ì´í„° + ë°°ì—´)
        from src.database.repository import FeatureSetRepository
        repo = FeatureSetRepository()
        repo.save_feature_set(
            X, y,
            feature_columns=feature_columns,
            target_columns=target_columns,
            pipeline_run_id=pipeline_run_id,
            scaler_params=scaler_params,
            encoder_classes=encoder_classes,
            source_row_count=X.shape[0],
        )

        return sizes

    def load(self, split: str) -> tuple[np.ndarray, np.ndarray]:
        """
        ì €ì¥ëœ ë°ì´í„° ë¡œë“œ.

        Args:
            split: "train" | "val" | "test"
        """
        X = io.load_numpy(f"{self._dir}/X_{split}.npy")
        y = io.load_numpy(f"{self._dir}/y_{split}.npy")
        return X, y