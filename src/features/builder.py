"""
ğŸ“ src/features/builder.py
===========================
í”¼ì²˜ ë¹Œë” â€” ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì˜ í•µì‹¬.

[íŒ¨í„´] Pipeline Pattern â€” sklearn Pipelineì²˜ëŸ¼ ì—¬ëŸ¬ ë³€í™˜ ë‹¨ê³„ë¥¼ ì²´ì´ë‹
[ì—­í• ] ì¸ì½”ë”© â†’ íŒŒìƒë³€ìˆ˜ â†’ ìŠ¤ì¼€ì¼ë§ì„ ìˆœì„œëŒ€ë¡œ ì ìš©í•©ë‹ˆë‹¤.
[ìœ„ì¹˜] 03_processed â†’ 04_features ë‹¨ê³„

í•µì‹¬ ì›ì¹™:
- fit_transform()ì€ í•™ìŠµ ë°ì´í„°ì—ë§Œ í˜¸ì¶œ (í†µê³„ê°’ í•™ìŠµ)
- transform()ì€ ê²€ì¦/í…ŒìŠ¤íŠ¸/ì¶”ë¡ ì— í˜¸ì¶œ (í•™ìŠµëœ í†µê³„ê°’ ì ìš©)
- ì´ êµ¬ë¶„ì„ ì§€í‚¤ì§€ ì•Šìœ¼ë©´ ë°ì´í„° ëˆ„ìˆ˜(data leakage)ê°€ ë°œìƒí•©ë‹ˆë‹¤!
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler

from config.feature_config import FEATURE_CONFIG
from src.utils.logger import get_logger
from src.utils import io

logger = get_logger(__name__)


class FeatureBuilder:
    """
    í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸.

    ì‚¬ìš©ë²•:
        builder = FeatureBuilder()

        # í•™ìŠµ ì‹œ â€” í†µê³„ê°’(í‰ê· , í‘œì¤€í¸ì°¨ ë“±)ì„ í•™ìŠµ
        X_train, y_train = builder.fit_transform(df_train)

        # ì¶”ë¡  ì‹œ â€” í•™ìŠµëœ í†µê³„ê°’ìœ¼ë¡œ ë³€í™˜ë§Œ
        X_new = builder.transform(df_new)

        # ì „ì²˜ë¦¬ê¸° ì €ì¥/ë¡œë“œ
        builder.save_artifacts("models/artifacts/")
        builder = FeatureBuilder.load_artifacts("models/artifacts/")
    """

    def __init__(self):
        self._label_encoders: dict[str, LabelEncoder] = {}
        self._scaler: StandardScaler = StandardScaler()
        self._feature_columns: list[str] = []
        self._is_fitted: bool = False

    # ================================================================
    # ê³µê°œ API
    # ================================================================

    def fit_transform(self, df: pd.DataFrame) -> tuple[np.ndarray, np.ndarray]:
        """
        í•™ìŠµ ë°ì´í„°ì— ë§ì¶° ì „ì²˜ë¦¬ê¸°ë¥¼ í•™ìŠµ(fit)í•˜ê³  ë³€í™˜(transform)í•©ë‹ˆë‹¤.

        Args:
            df: 03_processed ë°ì´í„° (í”¼ì²˜ + íƒ€ê²Ÿ í¬í•¨)

        Returns:
            (X, y) â€” X: [N, feature_dim], y: [N, target_count]
        """
        df = df.copy()
        logger.info("fit_transform ì‹œì‘: %dí–‰ Ã— %dì—´", *df.shape)

        # 1) íŒŒìƒ ë³€ìˆ˜ ìƒì„±
        df = self._create_derived_features(df)

        # 2) ë²”ì£¼í˜• ì¸ì½”ë”© (fit)
        for col in FEATURE_CONFIG.categorical:
            if col in df.columns:
                le = LabelEncoder()
                df[col] = le.fit_transform(df[col].astype(str))
                self._label_encoders[col] = le

        # 3) í”¼ì²˜/íƒ€ê²Ÿ ë¶„ë¦¬
        feature_cols = self._get_feature_columns(df)
        self._feature_columns = feature_cols

        X = df[feature_cols].values.astype(np.float32)
        y = df[[t for t in FEATURE_CONFIG.targets if t in df.columns]].values.astype(np.float32)

        # 4) ìˆ˜ì¹˜ ìŠ¤ì¼€ì¼ë§ (fit)
        X = self._scaler.fit_transform(X)

        self._is_fitted = True
        logger.info("fit_transform ì™„ë£Œ: X=%s, y=%s", X.shape, y.shape)
        return X, y

    def transform(self, df: pd.DataFrame) -> np.ndarray:
        """
        ìƒˆ ë°ì´í„°ì— í•™ìŠµëœ ì „ì²˜ë¦¬ë¥¼ ì ìš©í•©ë‹ˆë‹¤ (ì¶”ë¡ ìš©).

        âš ï¸ fit_transform() ë˜ëŠ” load_artifacts() í›„ì—ë§Œ í˜¸ì¶œ ê°€ëŠ¥
        """
        if not self._is_fitted:
            raise RuntimeError("fit_transform() ë˜ëŠ” load_artifacts()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”")

        df = df.copy()
        df = self._create_derived_features(df)

        # ë²”ì£¼í˜• ì¸ì½”ë”© (í•™ìŠµëœ encoder ì‚¬ìš©)
        for col, le in self._label_encoders.items():
            if col in df.columns:
                df[col] = df[col].astype(str).apply(
                    lambda x: le.transform([x])[0] if x in le.classes_ else -1
                )

        X = df[self._feature_columns].values.astype(np.float32)
        X = self._scaler.transform(X)
        return X

    def save_artifacts(self, dir_path: str) -> None:
        """ì „ì²˜ë¦¬ê¸°(scaler, encoder)ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        io.save_pickle(self._label_encoders, f"{dir_path}/label_encoders.pkl")
        io.save_pickle(self._scaler, f"{dir_path}/scaler.pkl")
        io.save_pickle(self._feature_columns, f"{dir_path}/feature_columns.pkl")
        logger.info("Artifacts ì €ì¥ ì™„ë£Œ: %s", dir_path)

    @classmethod
    def load_artifacts(cls, dir_path: str) -> "FeatureBuilder":
        """ì €ì¥ëœ ì „ì²˜ë¦¬ê¸°ë¥¼ ë¡œë“œí•˜ì—¬ ìƒˆ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        builder = cls()
        builder._label_encoders = io.load_pickle(f"{dir_path}/label_encoders.pkl")
        builder._scaler = io.load_pickle(f"{dir_path}/scaler.pkl")
        builder._feature_columns = io.load_pickle(f"{dir_path}/feature_columns.pkl")
        builder._is_fitted = True
        logger.info("Artifacts ë¡œë“œ ì™„ë£Œ: %s", dir_path)
        return builder

    # ================================================================
    # íŒŒìƒ ë³€ìˆ˜ ìƒì„± (ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜)
    # ================================================================

    def get_scaler_params(self) -> dict:
        """StandardScaler íŒŒë¼ë¯¸í„°ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ dictë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not self._is_fitted:
            return {}
        return {
            "mean": self._scaler.mean_.tolist(),
            "scale": self._scaler.scale_.tolist(),
            "var": self._scaler.var_.tolist(),
        }

    def get_encoder_classes(self) -> dict:
        """LabelEncoder í´ë˜ìŠ¤ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ dictë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            col: le.classes_.tolist()
            for col, le in self._label_encoders.items()
        }

    # ================================================================
    # íŒŒìƒ ë³€ìˆ˜ ìƒì„± (ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜)
    # ================================================================

    def _create_derived_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ì›ë³¸ í”¼ì²˜ì—ì„œ ìƒˆë¡œìš´ í”¼ì²˜ë¥¼ íŒŒìƒí•©ë‹ˆë‹¤.

        ë„ë©”ì¸ ì „ë¬¸ê°€ì˜ ì§€ì‹ì„ ì½”ë“œë¡œ í‘œí˜„í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.
        í”¼ì²˜ë¥¼ ì¶”ê°€í•˜ë ¤ë©´ ì´ ë©”ì„œë“œì— ì¶”ê°€í•˜ì„¸ìš”.
        """
        # 1) ì„ëŒ€ë£Œ ë¶€ë‹´ë¥  = ì—°ê°„ ì„ëŒ€ë£Œ / íˆ¬ìê¸ˆ
        if {"monthly_rent", "initial_investment"}.issubset(df.columns):
            df["rent_burden_ratio"] = (
                                              df["monthly_rent"] * 12
                                      ) / (df["initial_investment"].replace(0, 1))

        # 2) í‰ë‹¹ íˆ¬ìê¸ˆ = íˆ¬ìê¸ˆ / ë§¤ì¥ í¬ê¸°
        if {"initial_investment", "store_size_sqm"}.issubset(df.columns):
            df["investment_per_sqm"] = (
                                           df["initial_investment"]
                                       ) / (df["store_size_sqm"].replace(0, 1))

        # 3) 1ì¸ë‹¹ íˆ¬ìê¸ˆ = íˆ¬ìê¸ˆ / (ì§ì›ìˆ˜ + 1)
        if {"initial_investment", "employee_count"}.issubset(df.columns):
            df["investment_per_person"] = (
                                              df["initial_investment"]
                                          ) / (df["employee_count"] + 1)

        # 4) ê²½ìŸ ê³¼ë°€ ì—¬ë¶€
        if "nearby_competitor_count" in df.columns:
            df["is_high_competition"] = (df["nearby_competitor_count"] > 10).astype(int)

        # 5) ì²­ë…„/ì‹œë‹ˆì–´ ì°½ì—… ì—¬ë¶€
        if "age" in df.columns:
            df["is_young"] = (df["age"] < 30).astype(int)
            df["is_senior"] = (df["age"] >= 50).astype(int)

        # 6) ë¬´ê²½í—˜ ë…ë¦½ì°½ì—… (ê°€ì¥ ë¦¬ìŠ¤í¬ ë†’ì€ ì¡°í•©)
        if {"has_related_experience", "is_franchise"}.issubset(df.columns):
            df["inexperienced_independent"] = (
                    (df["has_related_experience"] == 0) & (df["is_franchise"] == 0)
            ).astype(int)

        return df

    def _get_feature_columns(self, df: pd.DataFrame) -> list[str]:
        """
        ì‚¬ìš©í•  í”¼ì²˜ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ (í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ë°©ì‹).

        [ìˆ˜ì • ì´ìœ ]
        ê¸°ì¡´: ë¸”ë™ë¦¬ìŠ¤íŠ¸(ì œì™¸í•  ê²ƒë§Œ ì§€ì •) â†’ API ì›ë³¸ ì»¬ëŸ¼(ctprvnCd ë“±)ì´ ì„ì„
        ìˆ˜ì •: í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸(ì‚¬ìš©í•  ê²ƒë§Œ ì§€ì •) â†’ feature_configì— ì •ì˜ëœ ê²ƒ + íŒŒìƒë³€ìˆ˜ë§Œ ì‚¬ìš©

        ì´ë ‡ê²Œ í•˜ë©´ ê³µê³µë°ì´í„° ì›ë³¸ ì»¬ëŸ¼ì´ ì•„ë¬´ë¦¬ ë§ì•„ë„
        ìš°ë¦¬ê°€ ì •ì˜í•œ í”¼ì²˜ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
        # 1) feature_configì— ì •ì˜ëœ í”¼ì²˜
        allowed = set(FEATURE_CONFIG.numerical + FEATURE_CONFIG.categorical + FEATURE_CONFIG.binary)

        # 2) _create_derived_features()ì—ì„œ ìƒì„±í•œ íŒŒìƒ í”¼ì²˜
        derived = {
            "rent_burden_ratio", "investment_per_sqm", "investment_per_person",
            "is_high_competition", "is_young", "is_senior", "inexperienced_independent",
        }
        allowed |= derived

        # 3) dfì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ê³  + ìˆ˜ì¹˜í˜•ì¸ ì»¬ëŸ¼ë§Œ ì„ íƒ
        return [
            c for c in df.columns
            if c in allowed and df[c].dtype in ("int64", "float64", "int32", "float32")
        ]