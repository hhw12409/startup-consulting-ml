"""
ğŸ“ src/models/xgboost_model.py
================================
XGBoost ê¸°ë°˜ ì°½ì—… ì˜ˆì¸¡ ëª¨ë¸.

[íŒ¨í„´] Strategy â€” BaseModel ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„
[ì—­í• ] ì •í˜• ë°ì´í„°ì—ì„œ ë¹ ë¥´ê³  ê°•ë ¥í•œ baseline ëª¨ë¸
[ê¶Œì¥] ë°ì´í„° 1ë§Œê±´ ì´í•˜ì¼ ë•Œ ì´ ëª¨ë¸ë¶€í„° ì‹œì‘í•˜ì„¸ìš”

íŠ¹ì§•:
  - íƒœìŠ¤í¬ë³„ ë…ë¦½ ëª¨ë¸ (ë¶„ë¥˜ 2ê°œ + íšŒê·€ 4ê°œ)
  - Feature Importance í™•ì¸ ê°€ëŠ¥
  - í•™ìŠµ ì‹œê°„ì´ ì§§ì•„ ë¹ ë¥¸ ì‹¤í—˜ ê°€ëŠ¥
"""

import pickle
from pathlib import Path
from typing import Any, Optional

import numpy as np
import xgboost as xgb

from src.models.base import BaseModel
from config.model_config import XGBOOST_CONFIG
from src.utils.logger import get_logger

logger = get_logger(__name__)


class XGBoostModel(BaseModel):
    """
    XGBoost Multi-task ëª¨ë¸.

    ì‚¬ìš©ë²•:
        model = XGBoostModel()
        model.train(X_train, y_train, X_val, y_val)
        preds = model.predict(X_test)
        model.save("models/registry/v1/xgboost")
    """

    # íƒœìŠ¤í¬ ì •ì˜: (ì´ë¦„, íƒ€ê²Ÿ ì»¬ëŸ¼ ì¸ë±ìŠ¤, ìœ í˜•)
    TASKS = [
        ("survival_1yr", 0, "classifier"),
        ("survival_3yr", 1, "classifier"),
        ("revenue",      2, "regressor"),
        ("profit",       3, "regressor"),
        ("risk",         4, "regressor"),
        ("break_even",   5, "regressor"),
    ]

    def __init__(self, config: Any = None):
        cfg = config or XGBOOST_CONFIG
        self._params = {
            "n_estimators": cfg.n_estimators,
            "max_depth": cfg.max_depth,
            "learning_rate": cfg.learning_rate,
            "subsample": cfg.subsample,
            "colsample_bytree": cfg.colsample_bytree,
            "min_child_weight": cfg.min_child_weight,
            "random_state": cfg.random_state,
        }
        self._models: dict[str, Any] = {}
        self._is_trained = False

    @property
    def name(self) -> str:
        return "XGBoostModel"

    def train(self, X_train, y_train, X_val=None, y_val=None):
        logger.info("=== XGBoost í•™ìŠµ ì‹œì‘ (%d íƒœìŠ¤í¬) ===", len(self.TASKS))

        for task_name, col_idx, task_type in self.TASKS:
            logger.info("  í•™ìŠµ ì¤‘: %s (%s)", task_name, task_type)

            if task_type == "classifier":
                model = xgb.XGBClassifier(**self._params, objective="binary:logistic", eval_metric="logloss")
                yt = (y_train[:, col_idx] > 0.5).astype(int)
                yv = (y_val[:, col_idx] > 0.5).astype(int) if y_val is not None else None
            else:
                model = xgb.XGBRegressor(**self._params, objective="reg:squarederror")
                yt = y_train[:, col_idx]
                yv = y_val[:, col_idx] if y_val is not None else None

            eval_set = [(X_val, yv)] if yv is not None else None
            model.fit(X_train, yt, eval_set=eval_set, verbose=False)
            self._models[task_name] = model

        self._is_trained = True
        logger.info("=== XGBoost í•™ìŠµ ì™„ë£Œ ===")
        return {"train_loss": [], "val_loss": []}

    def predict(self, X: np.ndarray) -> dict[str, np.ndarray]:
        if not self._is_trained:
            raise RuntimeError("í•™ìŠµë˜ì§€ ì•Šì€ ëª¨ë¸")

        # ìƒì¡´í™•ë¥  (ë¶„ë¥˜ â†’ predict_proba)
        p1 = self._models["survival_1yr"].predict_proba(X)[:, 1:]
        p3 = self._models["survival_3yr"].predict_proba(X)[:, 1:]

        return {
            "survival":   np.hstack([p1, p3]),
            "revenue":    np.column_stack([
                self._models["revenue"].predict(X),
                self._models["profit"].predict(X),
            ]),
            "risk":       self._models["risk"].predict(X).reshape(-1, 1).clip(0, 1),
            "break_even": self._models["break_even"].predict(X).reshape(-1, 1).clip(1, None),
        }

    def save(self, path: str) -> None:
        Path(path).parent.mkdir(parents=True, exist_ok=True)
        with open(f"{path}.pkl", "wb") as f:
            pickle.dump(self._models, f)
        logger.info("ëª¨ë¸ ì €ì¥: %s.pkl", path)

    def load(self, path: str) -> None:
        with open(f"{path}.pkl", "rb") as f:
            self._models = pickle.load(f)
        self._is_trained = True
        logger.info("ëª¨ë¸ ë¡œë“œ: %s.pkl", path)

    def get_feature_importance(self, feature_names: list[str] = None) -> dict[str, list]:
        """í”¼ì²˜ ì¤‘ìš”ë„ ë°˜í™˜ (XGBoost ê³ ìœ  ê¸°ëŠ¥)"""
        importance = {}
        for task_name, model in self._models.items():
            scores = model.feature_importances_
            if feature_names:
                importance[task_name] = sorted(
                    zip(feature_names, scores), key=lambda x: -x[1]
                )[:10]  # ìƒìœ„ 10ê°œ
            else:
                importance[task_name] = scores.tolist()
        return importance

    def get_info(self) -> dict[str, Any]:
        return {
            "name": self.name,
            "type": "xgboost",
            "tasks": list(self._models.keys()),
            "params": self._params,
            "is_trained": self._is_trained,
        }