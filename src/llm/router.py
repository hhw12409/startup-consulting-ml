"""
ğŸ“ src/llm/router.py
======================
LLM ë¼ìš°í„° â€” Ollama ë‹¨ë… ì‚¬ìš©.

[íŒ¨í„´] Facade â€” LLM í˜¸ì¶œì„ ë‹¨ìˆœí•œ ì¸í„°í˜ì´ìŠ¤ë¡œ ì œê³µ

ë™ì‘:
  1. Ollama ì‹¤í–‰ ì¤‘ì´ë©´ â†’ Ollama ì‚¬ìš© (í•œêµ­ì–´ ëª¨ë¸ ìë™ íƒì§€)
  2. Ollama ë¯¸ì‹¤í–‰ â†’ ê·œì¹™ ê¸°ë°˜ í…œí”Œë¦¿ í´ë°± (LLM ì—†ì´ ë™ì‘)
"""

from typing import Optional

from src.llm.base import BaseLLM
from src.llm.ollama_client import OllamaClient
from src.utils.logger import get_logger

logger = get_logger(__name__)


class LLMRouter:
    """
    LLM ë¼ìš°í„° (Ollama ë‹¨ë…).

    ì‚¬ìš©ë²•:
        router = LLMRouter()
        response = router.generate("ë¶„ì„í•´ì£¼ì„¸ìš”")
        print(router.active_llm)  # "Ollama (gemma2:9b)"
    """

    def __init__(self):
        self._client = OllamaClient()
        self._available = self._client.is_available()

        if self._available:
            logger.info("âœ… LLM í™œì„±: %s", self._client.name)
        else:
            logger.warning("âš ï¸ Ollama ë¯¸ì‹¤í–‰ â†’ ê·œì¹™ ê¸°ë°˜ í…œí”Œë¦¿ ëª¨ë“œ")
            logger.warning("   ì‹œì‘: ollama serve && ollama pull gemma2:9b")

    @property
    def active_llm(self) -> str:
        """í˜„ì¬ í™œì„± LLM ì´ë¦„"""
        return self._client.name if self._available else "ê·œì¹™ ê¸°ë°˜ í…œí”Œë¦¿"

    @property
    def is_llm_available(self) -> bool:
        return self._available

    def generate(
            self,
            prompt: str,
            system: Optional[str] = None,
            max_tokens: int = 2000,
            temperature: float = 0.7,
    ) -> str:
        """í…ìŠ¤íŠ¸ ìƒì„±. Ollama ë¶ˆê°€ ì‹œ í´ë°± ë©”ì‹œì§€ ë°˜í™˜."""
        if self._available:
            try:
                return self._client.generate(prompt, system, max_tokens, temperature)
            except Exception as e:
                logger.warning("Ollama í˜¸ì¶œ ì‹¤íŒ¨: %s â†’ í´ë°±", e)

        return "[LLM ë¯¸ì—°ê²°] Ollamaë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”: ollama serve && ollama pull gemma2:9b"