# ============================================================
# ğŸš€ ì°½ì—… ì»¨ì„¤í„´íŠ¸ AI â€” ì‹¤í–‰ ëª…ë ¹ì–´ ëª¨ìŒ
# ============================================================
# ì‚¬ìš©ë²•: make <ëª…ë ¹ì–´>
# ============================================================

.PHONY: install collect collect-regions feature train train-dl evaluate serve test clean help

# â”€â”€ ë„ì›€ë§ (ê¸°ë³¸) â”€â”€
help:
	@echo ""
	@echo "  ì°½ì—… ì»¨ì„¤í„´íŠ¸ AI â€” ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´"
	@echo "  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo ""
	@echo "  ì´ˆê¸° ì„¤ì •:"
	@echo "    make install         ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜"
	@echo ""
	@echo "  ë°ì´í„°:"
	@echo "    make collect         ê³µê³µë°ì´í„° APIì—ì„œ ìƒê°€ ë°ì´í„° ìˆ˜ì§‘"
	@echo "    make collect-regions ë²•ì •ë™ì½”ë“œ ìˆ˜ì§‘ (ì„œìš¸ì‹œ ê¸°ë³¸)"
	@echo "    make feature         í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ì •ì œëœ ë°ì´í„° â†’ í•™ìŠµìš© ë³€í™˜)"
	@echo ""
	@echo "  í•™ìŠµ:"
	@echo "    make train        XGBoost ëª¨ë¸ í•™ìŠµ (ê¸°ë³¸, ê¶Œì¥)"
	@echo "    make train-dl     PyTorch ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ"
	@echo ""
	@echo "  í‰ê°€:"
	@echo "    make evaluate     ì €ì¥ëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€"
	@echo ""
	@echo "  ì„œë²„:"
	@echo "    make serve        API ì„œë²„ ì‹¤í–‰ (localhost:8000)"
	@echo ""
	@echo "  í…ŒìŠ¤íŠ¸:"
	@echo "    make test         ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
	@echo "    make test-unit    ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë§Œ"
	@echo "    make test-integ   í†µí•© í…ŒìŠ¤íŠ¸ë§Œ"
	@echo ""
	@echo "  ê¸°íƒ€:"
	@echo "    make clean        ìºì‹œ/ì„ì‹œ íŒŒì¼ ì •ë¦¬"
	@echo "    make help         ì´ ë„ì›€ë§ í‘œì‹œ"
	@echo ""

# â”€â”€ ì´ˆê¸° ì„¤ì • â”€â”€
install:
	pip install -r requirements.txt

# â”€â”€ ë°ì´í„° ìˆ˜ì§‘ â”€â”€
collect-hdong:
	python scripts/run_collect_hdong_codes.py

collect-regions:
	python scripts/run_collect_region_codes.py

collect:
	python scripts/run_collect.py

# â”€â”€ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ â”€â”€
feature:
	python scripts/run_feature.py

# â”€â”€ ëª¨ë¸ í•™ìŠµ â”€â”€
train:
	python scripts/run_train.py --model xgboost

train-dl:
	python scripts/run_train.py --model neural_net

# â”€â”€ ëª¨ë¸ í‰ê°€ â”€â”€
evaluate:
	python scripts/run_evaluate.py

# â”€â”€ API ì„œë²„ â”€â”€
serve:
	python scripts/run_server.py

# â”€â”€ í…ŒìŠ¤íŠ¸ â”€â”€
test:
	python -m pytest tests/ -v

test-unit:
	python -m pytest tests/unit/ -v

test-integ:
	python -m pytest tests/integration/ -v

# â”€â”€ ì •ë¦¬ â”€â”€
clean:
	find . -type d -name __pycache__ -exec rm -rf {} +
	rm -rf .pytest_cache

# â”€â”€ ë°ì´í„°ë² ì´ìŠ¤ â”€â”€
db-up:
	docker-compose up -d

db-down:
	docker-compose down

db-init:
	python -c "from src.database.connection import init_db; init_db()"

db-reset:
	docker-compose down -v && docker-compose up -d

db-migrate:
	python scripts/run_migrate_to_db.py

# â”€â”€ LLM ì„¤ì • â”€â”€
setup-ollama:
	bash scripts/setup_ollama.sh

# â”€â”€ RAG ë²¡í„°DB â”€â”€
build-rag:
	python scripts/run_build_rag.py

build-rag-test:
	python scripts/run_build_rag.py --max 1000